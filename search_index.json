[{"slug":"cpp_beauty","title":"The Beauty of C++","author":"Matt Piekenbrock","date":"2017-03-01","categories":["C++"],"tags":["post"],"content":"Most code written today in some way shape or form is either written in or depends on C This includes for example most of the modern interpreted languages C is a beautiful language There I said it Before I get my inbox flooded with snippets of the ugliness of templates or links showing the differences hear me out C is an apple not an orange C is typically thought of as an ugly language Many devs who say this will far too quickly point to examples showing how many more lines it takes to write something in C than in Python For example This is a strawmans argument C is a compiled language Python Ruby R Perl etc are interpreted languages It is simply not fair to compare them Lets assume the contrary that it is fair to compare them After all if two given sets of source code encode the same logic why not start looking effiencytoproductivity ratios and maximize accordingly One of the core principles that has always been a philosophical cornerstone of C is the principle of zerocost abstraction That is the notion that if one intends to add something to the language it ought to be better than any code 99 of programmers could code up themselves More exactly the code should not just add higherorder functionalityit must offer an abstraction that the programmer can use effectively at zero or nearzero cost to themselves Here is a very deep statement maintaining the zerocost abstraction principle is hard It is hard to write abstractions that come at no cost to the programmer Lets see some examples Abstractions are easy Good abstractions are hard This begs the question how does one create an abstraction that is zerocost A famous quote that rings truer to closer one gets to the hardware is the following All problems in computer science can be solved by another level of indirection except for the problem of too many layers of indirection Well to me there are two aspects to it each being difficult in very different ways Theres the efficiency side of it a zerocost abstraction ought to be just as efficient as something a programmer might write himeself This to me comes down to an engineering problemensure the number of assembly instructions generated by the abstraction is minimal Then theres the much more difficult side of it the design aspect The abstraction should solve a problem not already solved by other constructions This is truly the most difficult aspect of all Design is a search problem Ill quote Mike Bostock here Talking about design is hard because design is hard Theres quite a lot of code out there But every programmer who has thought about any previous code theyve ever written has inevitably had the following experience Write a function that does something Write a function that works with the first function Realize that the first function can be encapsulated by the second Another aspect of design is the it is subjective What is working Functional programming Compiletime expressions SFINAE and its emergent simplicity httpswwwyoutubecomwatchvPFdWqa68LmAampfeatureyoutube The Monad example Computer programming encodes logic And anyone that studied functional programming knows that a sort of corner of of functional programming theory is something known category theory Lets look at a simple example stdoptional and relationship to monad Error codes and exception handling has been around for years How does one approach the problem of handling the result of a function which may fail to produce an output What if you want a function to return some object A common approach is to create some kind null object or to return a pointer to the object and return a nullptr In the former case the object may be expensive to create The latter case can be used but it is hard to compose You still need to perform checking somewhere either preconditions Navigating the stars Bartosz Mileweski proposed using Haskell as a language to design the TMP for C Picture of waveforms vs music notes More realworld examples kdtools C is about taking an existing set of tools and really looking deep at how they might be used differently in a completely new way The result is often a new feature of the language added either explicitly or discovered and used later on For example in 198x C released support for classes But now lambdas are just objects with a different syntax Thats an explicit example Another example implicit is inheritence which came with object oriented programming Inheritence is generally regarded as evil and practicioners often advise against it preferring composition instead There are many ways of achieving composition in C strategy pattern delegation pattern higherorder functions visitor pattern one example that emphasizes that components must be reuseable and small is the development of mixins mixins are really just abusing CRTP Conclusions Anyone can create a simple language to do whatever abstraction they could dream of The fact that C demands its abstractions to be zercost is a highly nontrivial constraint to satisfy Yet time passes Advances are made The fact that the lambda was a gamechanger C is an evolving language and advances in making these abstractions is becoming more popular Indeed there are some tasks that one can write incredibly concisely in modern C that is near the linecount and readability of some of the interpreted languages And in all but pathological misconstrewed examples the C solution will be faster than the interpreseted equivalents by design And how did that happen Intrinsically simple carefully thought out components were skillfully woven together in a way that carried no baggage no extraneous cost The result is simple to read simple to write code that solves a complex problem by breaking it into simple parts To me that is what makes C a beautiful language "},{"slug":"cpp_functional","title":"Is C++ a Functional Programming Language?","author":"Matt Piekenbrock","date":"2017-03-01","categories":["C++"],"tags":["post"],"content":" Functional Programming What is a functional programming FP language Definitions vary Here are a few A FP languages is any language which has a wealth of support for things typically associated with the FP paradigm A FP language typically involving composing pure functions avoiding shared state mutable data and sideeffects A FP language is sometimes also defined as a language which treats functions as firstclass citizens FP is sometimes considerd a declarative style of programming because the program logic is expressed through the compositions of pure functions which transform values into new values rather than constantly updating the internal state of existing variables eg as one might in the OOP paradigm with member fields Consider the 3rd definition of a FP language in the list above as it is the explicit Generally a language that treats a type T as a firstclass citizen means essentially that the language has mechanisms supporting the use of T types in ways similar to its support for its native types For example in C an int is a native type which one can do just about anything you want with at the language level eg you can make int variables pass int references create int pointers etc Stricter definitions of firstclass citizens require said types to be passable as arguments to functions returnable from function calls and assignable to variables Thus a FP language by definition 3 is just a language that supports some notion of a function type natively Under this definition Python qualifies as a FP language as it supports functions as firstclass citizens python def addx y returnx y def mulxy returnx y def evalbinarya b f returnfab mybinaryop add evalbinary45mybinaryop 9 mybinaryop mul evalbinary45mybinaryop 20 You can do imitate this with function pointers in C via something like cpp double adddouble x double y returnx y double muldouble x double y returnx y double evalbinarydouble a double b double fdouble double return fab One can either pass pointers to the function definitions directly or more generically via a variable assignment cpp double mybinaryopdouble double mybinaryop add evalbinary45mybinaryop 9 mybinaryop mul evalbinary45mybinaryop 20 This sparks the following question does C qualify as full fledged FP language under the above firstclasscitizen definition This article is dedicated to answering this question and to introducing a few basic ideas of FP along the way It is by no means comprehensive as general FP is a large topic area It may seem strange to interweave code examples written in Python with ones written in C these are two very different after all Nonetheless I conjecture understanding the nuances between how functions are implemented between these two languages illustrates nicely what is it really means to be a first class citizen It also demonstrates quite nicely how far weve come as a society with the newest version of C at masking machinelevel constraints with abstraction Basic Functional Programming Concepts Here are many of the terms tossed around in FP HigherOrder Functions a function that accepts another function as an argument Closure A function which encloses an environment An environment is just a data structure that binds symbols to values Currying the process of transforming a function that takes multiple arguments into a function that takes just a single argument and returns another function if any arguments are still needed Not to be confused with partial function application Pure Functions a function that does not enact side effects Since pure function cannot mutate the state of its arguments they must return a valueotherwise they are useless Functors in the context of FPhttpsstackoverflowcomquestions2030863infunctionalprogrammingwhatisafunctor a functor is a container of type a that when subjected to a function that maps from a b yields a container of type b Replacing the words container type and function with the words category object and morphism yields a similar definition of a functor in category theory Monad A monad is just a monoid in the category of endofunctorshttpsstackoverflowcomquestions3870088amonadisjustamonoidinthecategoryofendofunctorswhatstheproblem They enable things like the functional mutation of state in ways that adhere to FP principles Understanding monads is a like a spiritual experiencehttpsbartoszmilewskicom20110109monadsforthecuriousprogrammerpart1 that must be taken alone Immutable A variable is immutable if its value cannot change once its instantiated In pure FP languages all variables are immutable Tail recursion A type of recursion wherein there is one recursive call whose result is left unmodified at the end of the body fo the recursive function the tail and the recursive call is the last operation to occur There are many other basic terms one needs to be familiar with including memoization nullaryunarybinaryternary functions predicates delayed or lazy evaluation lambdas ycombinators etc Higher order functions and Closures A higher order function is a function that accepts a function as an argument Thus a programming language is not functional it does not support higher order since part of the definition of a function being a firstclass citizens is that it can be passed as an argument to a function Weve already defined the higher order function evalbinary which takes two numbers a and b and binary function f as input python def evalbinarya b f returnfab In the above code def was to define a named function A more compact style of defining a function is to define an anonymous function or lambda function python lambda abf fab Note there is no return statement needed for lambda functions its implicit in the last evaluated expression Since Python treats functions as first class citizens both named functions and lambas can be assigned to variables python g lambda abf fab Although the lambda is bound to the symbol g and thus can be referred to by name in general people will still refer to lambda functions as anonymous In most languages there are subtle differences between anonymous functions and named functions For example in Pythonhttpsstackoverflowcomquestions12264834whatisthedifferenceforpythonbetweenlambdaandregularfunction a lambda expression is an expression which evaluates to a function object while a def statement has no value its creates a function object and binds it to a name Moreover lambda definitions are limited to single expressions A common example of a popular higherorder function is map and reduce mapf iter takes as input a function f which it applies to every element along an iterable it It then returns an iterable map object which can be enumerated to store as an explicit collection For example python maplambda x x2 1 2 3 4 5 listmaplambda x x2 1 2 3 4 5 1 4 9 16 25 tuplemaplambda x x2 1 2 3 4 5 1 4 9 16 25 dictmaplambda x x x2 1 2 3 4 5 1 1 2 4 3 9 4 16 5 25 Sometimes its useful to have the function maintain an internal state A closure is a function that does just this it encapsulates its own lexical scope Closures are typically constructed using the factory pattern python def cycliccountern c 0 def incrementi1 nonlocal c c c i n returnc returnincrement counter cycliccounter10 counter 1 counter 2 counter10 12 Notice that the keyword nonlocal was used to denote the variable from the outer enclosing scope is writable In contrast since n is constant it is available without the nonlocal keyword designation See for this posthttpsstackoverflowcomquestions4020419whyarentpythonnestedfunctionscalledclosures and this posthttpsstackoverflowcomquestions1261875pythonnonlocalstatement for more information on Python closures and the nonlocal keyword"},{"slug":"getter_setter","title":" Getters and Setters are DEAD","author":"Matt Piekenbrock","date":"2017-02-01T00:00:00.000Z","categories":["programming"],"tags":["programming"],"content":" Getters and Setters are DEAD I remember learning that getter setter pattern vividly The original idea of the getter setter pattern was to keep the implementation hidden from the user as much as possible instead only expose the minimal interface needed to chaneg the member field value Said another way getters and setters are aimed at providing encapsulation or information hiding A typical usecase is that a getter would provide access to stored member type and a setting would allow mutation By encapsulating the readwrite functionality as functions one could have finer control over the object properties are used For example one might provide a read function that returns a property but only if the property is valid otherwise they might throw an exception Another example illustrates the use of settersby moving the assignment to a function that you control one can do stricter argument checking thereby ensuring the validitiy of the corresponding object instance The motivation behind getterssetters is sound encapsulation is a good thing However far too often what ends up happening especially in the beginnerlevel Java code is that the getters and setters get misused They can actually hinder the expressiveness of code and make it more difficult for people to actually use their class Heres an example of what not to do cpp class PointXYZ float x y z public float getx returnx void setxfloat x x x float gety returny void setyfloat y y y float getz returnz void setzfloat z z z As you can see this is a very simple class and weve following the getter setter pattern to the tee But a much simpler and better solution is to just treat it as POD type cpp struct PointXYZ float xyz No fancy constructors The problem though is that this is ugly and not necessary at all there are no restrictions imposed on the internal field values cpp template struct Property T value Propertyconst T initialvalue valueinitialvalue operator T return value T operator T newValue return value newValue cpp struct SetosaPlant Property sepallength Property sepalwidth int main auto plant SetosaPlant plantsepallength 5 plantsepalwidth plantsepallength cpp class SetosaPlant public Replace w stdoptional int sepallength returnsepallength SetosaPlant sepallengthT newvalue value newvalue returnthis private int sepallength int sepalwidth int main auto plant SetosaPlant plant sepallength5 sepalwidthplantsepallength "},{"slug":"my_rmd_post","title":"My RMD Post","author":"Matt Piekenbrock","date":"2017-02-01T00:00:00.000Z","categories":["R"],"tags":["post","R Markdown","plot","regression"],"content":" Testing LaTeX What Trying out latex x fx geq lambda R Markdown You can embed an R code chunk like this summarycars speed dist Min 40 Min 200 1st Qu120 1st Qu 2600 Median 150 Median 3600 Mean 154 Mean 4298 3rd Qu190 3rd Qu 5600 Max 250 Max 12000 fit lt lmdist speed data cars fit Call lmformula dist speed data cars Coefficients Intercept speed 17579 3932 Including Plots You can also embed plots See Figure 1 for example parmar c0 1 0 1 pie c280 60 20 c39Sky39 39Sunny side of pyramid39 39Shady side of pyramid39 col c390292D839 39F7EA3939 39C4B63239 initangle 50 border NA Figure 1 A fancy pie chart "},{"slug":"normal_distribution","title":"Why is the normal distribution bell shaped?","author":"Matt Piekenbrock","date":"2017-02-01T00:00:00.000Z","categories":["statistics"],"tags":["post","probability","statistics","distributions"],"content":"Perhaps the most persistent random pattern to appear in the universe itself is the normal distribution The Normal distibution also called the Gaussian distribution cpp double addvecdouble v1 double v2 int n double res mallocsizeofdoublen for int i 0 i n i resi v1i v2i return res Seem reasonable Maybe for parallel computing Its actually awful though Its up to the caller to deallocate memory manually even though its unclear that memory was even dynamically allocated in the first place Do we even need heapallocated memory A better solution is to rely on stdvector whose deconstructor manages the memory for you after the vector is returned and goes out of scope it deconstructs 2nd attempt cpp using stdvector vector addvecvector v1 vector v2 assertv1size v2size vector resv1size for int i 0 i ressize i resati v1ati v2ati return res This is safer much more STLlike and it removes the need for the extra argument But there are still many things one could improve for example the vectors above were passed byvalue which requires two vector copies Instead should pass them by reference with the ampersand operator cpp using stdvector vector addvecvector v1 vector v2 vector resv1size for int i 0 i ressize i resati v1ati v2ati return res Actually the vectors are not modified so they ought to be const to encourage the compiler to put them in some kind of readonly memory cpp using stdvector vector addvecvector const v1 vector const v2 vector resv1size for int i 0 i ressize i resati v1ati v2ati return res Its considered poor practice to use ints as loop counters since thats a signed type and it limits how big your vectors can be Much better is the stdsizet type Its portable more semantically clear more secure and most importantly guarenteed by the standard to be big enough for any container Additionally as an unsigned type no bits are wasted in the int case the sign bit is meaningless cpp using stdvector vector addvecvector const v1 vector const v2 vector resv1size for sizet i 0 i ressize i resati v1ati v2ati return res The at access method for vectors does boundchecking which amount to three function calls every loop iteration Better to check once and do a straight indexing cpp using stdvector vector addvecvector const v1 vector const v2 assertv1size v2size vector resv1size for sizet i 0 i ressize i resi v1i v2i return res Believe it or not incrementing via i used to generate one more instruction than i The former makes a copy and then increments whereas the latter just returns the final value See answer 3 of httpsstackoverflowcomquestions24886isthereaperformancedifferencebetweeniandiinc Also the size is a function call Notice it gets called in the conditional every iteration Better to use a const sizet to store the vector size to encourage getting put into a register cpp using stdvector vector addvecvector const v1 vector const v2 const sizet n v1size assertn v2size vector resn for sizet i 0 i n i resi v1i v2i return res Actually why even use a counter variable at all Vectors are guaranteed by the standard to be contiguous Which means we can just iterate through them via randomaccessiterators which are just incrementeablepointers to the vectors memory cpp using stdvector vector addvecvector const v1 vector const v2 assertv1size v2size vectorconstiterator it1 v1begin vectorconstiterator it2 v2begin vector resn vectoriterator out resbegin whileit1 v1end out it1 it2 out it1 it2 return res But that only works for doubles And maybe your boss wants your to use accept multiple numeric types So you can copypaste the function to work with floats and doubles But then what if someone has their own fancy floating point type There are many integer types see httpsencppreferencecomwcpplanguagetypesIntegertypes And fuck overloading all the possible floating point types In modern C one can use type traits to assert at compiletime via staticassert properties of the compiletypededuced type T See httpsencppreferencecomwcpptypesisfloatingpoint httpsstackoverflowcomquestions15433381performanceofpitercontendinforloop cpp using stdvector template vector addvecvector const v1 vector const v2 staticassertisfloatingpointvalue Must be floating point assertv1size v2size vectorconstiterator it1 v1begin vectorconstiterator it2 v2begin vector resn vectoriterator out resbegin whileit1 v1end out it1 it2 out it1 it2 return res Now we have one function that works for any floating point type But it looks terrible Can we use the standard library to simplify it without incurring any penalty from the optimized version we have Sure can See the C version of mapping httpwwwcpluspluscomreferencealgorithmtransform cpp template vector addvecconst vector v1 const vector v2 staticassertisfloatingpointvalue Must be floating point vector resv1size stdtransformv1begin v1end v2begin resbegin stdplus return res The second overload takes three input iterators an output iterator and a binary function templated by the floating point template type and applies the binary function pairwise to the two input iterators saving the result to the iterator specified as the output res If you look at the equivalent code on the site this is literally essentially equivalent to the on before but much less code and its just as efficient But this is still a function call And from the first link you saw how expensive setting up function calls can be It would be better if this code were just copypasted everywhere it was called Luckily you can do that moreorless with inline cpp using stdvector template inline vector addvecvector const v1 vector const v2 staticassertisfloatingpointvalue Must be floating point vector resv1size stdtransformv1begin v1end v2begin resbegin stdplus return res We can follow the tradition of specifying preconditions using narrow contractshttpwwwopenstdorgJTC1SC22WG21docspapers2015p0147r0htmlWideNarrow to remove the assertion and instead declare that if two vectors are given their sizes must match otherwise this function produces undefined behavior If we assume the preconditions are always met the memory accessed should never cause a segmentation fault That is it shouldnt throw any exceptions So we can append noexcept to tell the compiler to hint that this should be a safe function httpsstackoverflowcomquestions7593086whyusenonmemberbeginandendfunctionsinc11 cpp template inline vector addvecconst vector v1 const vector v2 staticassertisfloatingpointvalue Must be floating point vector resv1size transformbeginv1 endv1 beginv2 beginres plus return res c template nodiscard auto addvecconst vector v1 const vector v2 noexcept vector staticassertisfloatingpointvalue Must be floating point vector res resreservev1size transformbeginv1 endv1 beginv2 beginres plus return res So this is pretty good and its short But now consider an example useage cpp vector v1 1 2 3 vector v2 4 5 6 vector v3 7 8 9 vector res addvecv3 addvecv1v2 Ehh each addvec allocates a new and returns it so the last statement allocates two vectors Currently if you want to apply n vector additions you need n vector allocations to happen but if you replicated something like above function to add up not just two vectors but n vectors you could reimplement another function that takes some n vectors and only performs one vector allocation for the result How does one do that without making n special vector additions specializations We couldve done the easy solution in the beginning enact sideeffects by passing one by nonconst reference and modifying it directlyno copies needed But screw that I want a pure function Challenge to the mind Now the final example solution httpsenwikipediaorgwikiExpressiontemplates See the paragraph starting with A problem with this approach is that more complicated expressions such as Vec x a b c are implemented inefficiently The implementation first produces a temporary vector to hold a b then produces another vector with the elements of c added in Even with return value optimization this will allocate memory at least twice and require two loops The idea is to build the expression trees at compiletime to enable delayed evaluation and socalled loop fusion Also see the application section at the bottom for the modern linear algebra that use this kind of thing Of course the vector additions is just one example Notice that sentence that expression templates are used for ie for dealing with vectors and matrices of numbers So everything in scientific computing This notion of building compiletime abstract syntax trees to represent complex expressions its not just some lispderived lambda calculus motivated schemefunction mumbo jumbo Its a movement thats shaping the language which enables C programmers to create expressive terse functional code that is every drop as efficient as the hyper bittrick optimized oldfortran versions were But these tricks are general composable and are becoming increasingly simpler to implement And believe it or not at the cutting edge of the libraries proposing additions the standard lies extensions inspired by things like category theory monads are the primary example algebra posets are coming in c20 etc That is modern C and what is emerging with the newer standards"},{"slug":"vector_addition","title":"Vector addition","author":"Matt Piekenbrock","date":"2017-02-01T00:00:00.000Z","categories":["C++"],"tags":["post","tmp","programming","C++"],"content":"How would you implement vector addition two equallength vectors piecewise in C Your boss tells you to make it as efficient as possible because its going to be called exactly 5e9 times Whats the most efficient way to go about it Such a trivial operation after all You might say well Ill just import numpy or just whatever solution I can find online But thats not good enough Some of it may require engineering but consider it a challenge to the mind if you a computer scientist cannot even produce the mostefficient solution to something as trivial as vector addition what worth do you have First attempt cpp double addvecdouble v1 double v2 int n double res mallocsizeofdoublen for int i 0 i n i resi v1i v2i return res Seem reasonable Maybe for parallel computing Its actually awful though Its up to the caller to deallocate memory manually even though its unclear that memory was even dynamically allocated in the first place Do we even need heapallocated memory A better solution is to rely on stdvector whose deconstructor manages the memory for you after the vector is returned and goes out of scope it deconstructs 2nd attempt cpp using stdvector vector addvecvector v1 vector v2 assertv1size v2size vector resv1size for int i 0 i ressize i resati v1ati v2ati return res So whats wrong with this one The above passes the vectors byvalue which requires two vector copies Instead should pass them by reference with the ampersand operator cpp using stdvector vector addvecvector v1 vector v2 vector resv1size for int i 0 i ressize i resati v1ati v2ati return res Actually the vectors are not modified so they ought to be const to encourage the compiler to put them in some kind of readonly memory cpp using stdvector vector addvecvector const v1 vector const v2 vector resv1size for int i 0 i ressize i resati v1ati v2ati return res Its considered poor practice to use ints as loop counters since thats a signed type and it limits how big your vectors can be Much better is the stdsizet type Its portable more semantically clear more secure and most importantly guarenteed by the standard to be big enough for any container Additionally as an unsigned type no bits are wasted in the int case the sign bit is meaningless cpp using stdvector vector addvecvector const v1 vector const v2 vector resv1size for sizet i 0 i ressize i resati v1ati v2ati return res The at access method for vectors does boundchecking which amount to three function calls every loop iteration Better to check once and do a straight indexing cpp using stdvector vector addvecvector const v1 vector const v2 assertv1size v2size vector resv1size for sizet i 0 i ressize i resi v1i v2i return res Believe it or not incrementing via i used to generate one more instruction than i The former makes a copy and then increments whereas the latter just returns the final value See answer 3 of httpsstackoverflowcomquestions24886isthereaperformancedifferencebetweeniandiinc Also the size is a function call Notice it gets called in the conditional every iteration Better to use a const sizet to store the vector size to encourage getting put into a register cpp using stdvector vector addvecvector const v1 vector const v2 const sizet n v1size assertn v2size vector resn for sizet i 0 i n i resi v1i v2i return res Replacing counters with iterators Actually why even use a counter variable at all Vectors are guaranteed by the standard to be contiguous Which means we can just iterate through them via randomaccessiterators which are just incrementeablepointers to the vectors memory cpp using stdvector vector addvecvector const v1 vector const v2 assertv1size v2size vectorconstiterator it1 v1begin vectorconstiterator it2 v2begin vector resn vectoriterator out resbegin whileit1 v1end out it1 it2 out it1 it2 return res But that only works for doubles And maybe your boss wants your to use accept multiple numeric types So you can copypaste the function to work with floats and doubles But then what if someone has their own fancy floating point type There are many integer types see httpsencppreferencecomwcpplanguagetypesIntegertypes And fuck overloading all the possible floating point types In modern C one can use type traits to assert at compiletime via staticassert properties of the compiletypededuced type T See httpsencppreferencecomwcpptypesisfloatingpoint httpsstackoverflowcomquestions15433381performanceofpitercontendinforloop cpp using stdvector template vector addvecvector const v1 vector const v2 staticassertisfloatingpointvalue Must be floating point assertv1size v2size vectorconstiterator it1 v1begin vectorconstiterator it2 v2begin vector resn vectoriterator out resbegin whileit1 v1end out it1 it2 out it1 it2 return res Now we have one function that works for any floating point type But it looks terrible Can we use the standard library to simplify it without incurring any penalty from the optimized version we have Sure can See the C version of mapping httpwwwcpluspluscomreferencealgorithmtransform Towards functional roots cpp template vector addvecconst vector v1 const vector v2 staticassertisfloatingpointvalue Must be floating point vector resv1size stdtransformv1begin v1end v2begin resbegin stdplus return res The second overload takes three input iterators an output iterator and a binary function templated by the floating point template type and applies the binary function pairwise to the two input iterators saving the result to the iterator specified as the output res If you look at the equivalent code on the site this is literally essentially equivalent to the on before but much less code and its just as efficient But this is still a function call And from the first link you saw how expensive setting up function calls can be It would be better if this code were just copypasted everywhere it was called Luckily you can do that moreorless with inline cpp using stdvector template inline vector addvecvector const v1 vector const v2 staticassertisfloatingpointvalue Must be floating point vector resv1size stdtransformv1begin v1end v2begin resbegin stdplus return res We can follow the tradition of specifying preconditions using narrow contractshttpwwwopenstdorgJTC1SC22WG21docspapers2015p0147r0htmlWideNarrow to remove the assertion and instead declare that if two vectors are given their sizes must match otherwise this function produces undefined behavior If we assume the preconditions are always met the memory accessed should never cause a segmentation fault That is it shouldnt throw any exceptions So we can append noexcept to tell the compiler to hint that this should be a safe function httpsstackoverflowcomquestions7593086whyusenonmemberbeginandendfunctionsinc11 cpp template inline vector addvecconst vector v1 const vector v2 staticassertisfloatingpointvalue Must be floating point vector resv1size transformbeginv1 endv1 beginv2 beginres plus return res So this is pretty good and its short But now consider an example useage cpp vector v1 1 2 3 vector v2 4 5 6 vector v3 7 8 9 vector res addvecv3 addvecv1v2 Ehh each addvec allocates a new and returns it so the last statement allocates two vectors Currently if you want to apply n vector additions you need n vector allocations to happen but if you replicated something like above function to add up not just two vectors but n vectors you could reimplement another function that takes some n vectors and only performs one vector allocation for the result How does one do that without making n special vector additions specializations Expression Templates We couldve done the easy solution in the beginning enact sideeffects by passing one by nonconst reference and modifying it directlyno copies needed But screw that I want a pure function Challenge to the mind Now the final example solution httpsenwikipediaorgwikiExpressiontemplates See the paragraph starting with A problem with this approach is that more complicated expressions such as Vec x a b c are implemented inefficiently The implementation first produces a temporary vector to hold a b then produces another vector with the elements of c added in Even with return value optimization this will allocate memory at least twice and require two loops The idea is to build the expression trees at compiletime to enable delayed evaluation and socalled loop fusion Also see the application section at the bottom for the modern linear algebra that use this kind of thing Of course the vector additions is just one example Notice that sentence that expression templates are used for ie for dealing with vectors and matrices of numbers So everything in scientific computing This notion of building compiletime abstract syntax trees to represent complex expressions its not just some lispderived lambda calculus motivated schemefunction mumbo jumbo Its a movement thats shaping the language which enables C programmers to create expressive terse functional code that is every drop as efficient as the hyper bittrick optimized oldfortran versions were But these tricks are general composable and are becoming increasingly simpler to implement And believe it or not at the cutting edge of the libraries proposing additions the standard lies extensions inspired by things like category theory monads are the primary example algebra posets are coming in c20 etc That is modern C and what is emerging with the newer standards"}]